{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "def get_records():\n",
    "    \"\"\" Get paths for data in data/mit/ directory \"\"\"\n",
    "    #Download if doesn't exist\n",
    "    \n",
    "    # There are 3 files for each record\n",
    "    # *.atr is one of them\n",
    "    paths = glob.glob('mitbih/*.atr') # returns an array of path names that matches the arguement\n",
    "    #paths = [os.path.join(os.getcwd(),path) for path in paths]\n",
    "    # Get rid of the extension\n",
    "    paths = [path[:-4] for path in paths]\n",
    "    paths.sort()\n",
    "\n",
    "    return paths\n",
    "\n",
    "records = get_records()\n",
    "print ('There are {} record files'.format(len(records)))\n",
    "print (records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_annotations(annotation, type):\n",
    "    \"\"\" Get rid of non-beat markers \"\"\"\n",
    "    \"\"\"'N' for normal beats. Similarly we can give the input 'L' for left bundle branch block beats. 'R' for right bundle branch block\n",
    "        beats. 'A' for Atrial premature contraction. 'V' for ventricular premature contraction. '/' for paced beat. 'E' for Ventricular\n",
    "        escape beat.\"\"\"\n",
    "    \n",
    "    good = [type] \n",
    "    ids = np.in1d(annotation.symbol, good)\n",
    "\n",
    "    # We want to know only the positions\n",
    "    beats = annotation.sample[ids]\n",
    "\n",
    "    return beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A  --  Atrial premature beat\n",
    "E  --  Ventricular escape beat\n",
    "L  --  Left bundle branch block beat\n",
    "N or .  --  Normal beat\n",
    "R  --  Right bundle branch block beat\n",
    "V  --  Premature ventricular contraction\n",
    "!  --  Ventricular flutter wave\n",
    "/  --  Paced beat\n",
    "\"\"\"\n",
    "\n",
    "import wfdb\n",
    "\n",
    "def signal_segmentation(sig, type, output_dir=''):\n",
    "    count = 1\n",
    "    signals, fields = wfdb.rdsamp(sig, channels = [0])\n",
    "    ann = wfdb.rdann(sig, 'atr')\n",
    "    imp_beats = beat_annotations(ann, type)\n",
    "    beats = (ann.sample)\n",
    "    for i in tqdm(imp_beats):\n",
    "        beats = np.array(beats)\n",
    "        index_i = np.where(beats == i) # find the indexes (location tuples) of all imp_beats(desired annotated beats) inside the array of all beats\n",
    "        j = index_i[0][0] # as numpy.where returns tuples we only need the first index of item that match\n",
    "        if(j!=0 and j!=(len(beats)-1)):\n",
    "            # according to paper\n",
    "            sig_start = beats[j-1] + 20\n",
    "            sig_end = beats[j+1] - 20\n",
    "            data = signals[sig_start:sig_end, 0]\n",
    "            \n",
    "            # Plot and save the beat\n",
    "            fig = plt.figure(dpi=300, frameon=False, figsize=(1.0,0.5))\n",
    "            plt.plot(data, linewidth=0.5)\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "            filename = output_dir + 'fig_{}_{}'.format(sig[-3:],count) + '.png'  # sig[-3:] is the last 3 characters (mit-bih file number)\n",
    "            fig.savefig(filename)\n",
    "            plt.close()\n",
    "            im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "            im_gray = cv2.copyMakeBorder(im_gray,75,75,0,0, cv2.BORDER_REPLICATE) # as the image shape (from plt.savefig) is 300px*150px due to figsize=(1.0,0.5) and dpi=300 where dpi means dots(pixels) per inch\n",
    "            im_gray = cv2.resize(im_gray, (128, 128), interpolation=cv2.INTER_LANCZOS4)\n",
    "            cv2.imwrite(filename, im_gray)\n",
    "            print('img writtten {}'.format(filename))\n",
    "            count += 1\n",
    "        print('img completed {}'.format(sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating database by segmentation of ecg beats into image\n",
    "\n",
    "labels = ['A', 'L', 'N', '/', 'V', 'R', 'E', '!']\n",
    "output_dirs = ['APC/', 'LBBB/', 'NOR/', 'PAB/', 'PVC/', 'RBBB/', 'VEB/', 'VFE/']\n",
    "for type, output_dir in zip(labels, output_dirs):\n",
    "    result_dir = 'MIT-BIH_DATABASE/'+output_dir\n",
    "    partial_records = records[42:48]  # 6 elememts out of 48 elements iteration due to RAM shortage, e.g. from records[0] to records[5] -- 6 elememts\n",
    "    #print(partial_records)\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    for r in tqdm(partial_records):\n",
    "        signal_segmentation(r, type, output_dir=result_dir)\n",
    "\n",
    "# no need to run this block anymore after data creation(beat segmentation / ECG to beat image conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the length of different directory inside dataset and plot pie chart function\n",
    "\n",
    "def plot_pie_chart_of_data(data, labels, colors, figName_with_ext, figureSize=(10,10), center_white_circle_radius=0.7):\n",
    "    plt.figure(figsize=figureSize)\n",
    "    my_circle=plt.Circle((0,0), center_white_circle_radius, color='white')\n",
    "    plt.pie(data, labels= labels, colors= colors, autopct='%1.1f%%')\n",
    "    p=plt.gcf()\n",
    "    p.gca().add_artist(my_circle)\n",
    "    plt.show()\n",
    "    p.savefig(figName_with_ext, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the length of different directory inside dataset\n",
    "Database_DIR = 'MIT-BIH_DATABASE/'\n",
    "image_dirs = ['APC/', 'LBBB/', 'NOR/', 'PAB/', 'PVC/', 'VEB/', 'RBBB/', 'VFE/']\n",
    "\n",
    "no_of_files_in_dir=[]\n",
    "for image_dir in image_dirs:\n",
    "    path, dirs, files = next(os.walk(os.path.join(Database_DIR,image_dir)))\n",
    "    no_of_files_in_dir.append(len(files)) \n",
    "\n",
    "print('Number of images in each directory={} and total number of images={}'.format(no_of_files_in_dir, sum(no_of_files_in_dir)))\n",
    "\n",
    "labels = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'VEB', 'RBBB', 'VFE']\n",
    "colors = ['green','blue','red','skyblue','orange', 'yellow','magenta', 'cyan']\n",
    "\n",
    "plot_pie_chart_of_data(no_of_files_in_dir,labels,colors, 'data_distribution.png')\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "# plt.pie(no_of_files_in_dir, labels=['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'VEB', 'RBBB', 'VFE'], colors=['green','blue','red','skyblue','orange', 'yellow','magenta', 'cyan'],autopct='%1.1f%%')\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.show()\n",
    "# p.savefig('data_distribution.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data images into train, test subdirectory\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "image_dirs = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'RBBB', 'VEB', 'VFE']\n",
    "\n",
    "if os.path.isdir('MIT-BIH_DATABASE/train/APC') is False:\n",
    "    for i in image_dirs:\n",
    "        current_path = 'MIT-BIH_DATABASE/'+i\n",
    "        path_train = 'MIT-BIH_DATABASE/train/'+i\n",
    "        path_test = 'MIT-BIH_DATABASE/test/'+i\n",
    "        os.makedirs(path_train)\n",
    "        os.makedirs(path_test)\n",
    "        path, dirs, files = next(os.walk(current_path))\n",
    "        no_of_files = len(files)\n",
    "        no_of_test_dir_files = round(no_of_files*0.2)\n",
    "        no_of_train_dir_files = no_of_files - no_of_test_dir_files\n",
    "        print(no_of_files)\n",
    "        for j in random.sample(glob.glob(current_path+'/fig*'),no_of_train_dir_files):\n",
    "            shutil.move(j,path_train)\n",
    "        for j in random.sample(glob.glob(current_path+'/fig*'),no_of_test_dir_files):\n",
    "            shutil.move(j,path_test)\n",
    "        \n",
    "        \n",
    "# moving 80%,20% data from MIT-BIH_DATABASE/ directory to MIT-BIH_DATABASE/train, MIT-BIH_DATABASE/test subdirectory \n",
    "\n",
    "# no need to run this block anymore after data folder (train, test) creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the length of datas in train directory inside dataset\n",
    "Database_DIR = 'MIT-BIH_DATABASE/train/'\n",
    "image_dirs = ['APC/', 'LBBB/', 'NOR/', 'PAB/', 'PVC/', 'VEB/', 'RBBB/', 'VFE/']\n",
    "no_of_files_in_dir=[]\n",
    "for image_dir in image_dirs:\n",
    "    path, dirs, files = next(os.walk(os.path.join(Database_DIR,image_dir)))\n",
    "    no_of_files_in_dir.append(len(files)) \n",
    "\n",
    "print('Number of images in each directory={} and total number of images={}'.format(no_of_files_in_dir, sum(no_of_files_in_dir)))\n",
    "\n",
    "labels = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'VEB', 'RBBB', 'VFE']\n",
    "colors = ['green','blue','red','skyblue','orange', 'yellow','magenta', 'cyan']\n",
    "\n",
    "plot_pie_chart_of_data(no_of_files_in_dir, labels, colors, 'data_distribution_train_dir.png')\n",
    "\n",
    "# no need to run this block anymore after data folder (train, test) creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the length of datas in test directory inside dataset\n",
    "Database_DIR = 'MIT-BIH_DATABASE/test/'\n",
    "image_dirs = ['APC/', 'LBBB/', 'NOR/', 'PAB/', 'PVC/', 'VEB/', 'RBBB/', 'VFE/']\n",
    "no_of_files_in_dir=[]\n",
    "for image_dir in image_dirs:\n",
    "    path, dirs, files = next(os.walk(os.path.join(Database_DIR,image_dir)))\n",
    "    no_of_files_in_dir.append(len(files)) \n",
    "\n",
    "print('Number of images in each directory={} and total number of images={}'.format(no_of_files_in_dir, sum(no_of_files_in_dir)))\n",
    "\n",
    "labels = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'VEB', 'RBBB', 'VFE']\n",
    "colors = ['green','blue','red','skyblue','orange', 'yellow','magenta', 'cyan']\n",
    "\n",
    "plot_pie_chart_of_data(no_of_files_in_dir, labels, colors, 'data_distribution_test_dir.png')\n",
    "\n",
    "# no need to run this block anymore after data folder (train, test) creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Number of GPU available', len(public_devices))\n",
    "\n",
    "if len(public_devices) > 0:\n",
    "    for gpu in public_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # preventing tensorflow to allocate all gpu memory at start of declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation paper function\n",
    "def cropping(image, filename):\n",
    "    \n",
    "    #Left Top Crop\n",
    "    crop = image[:96, :96]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'leftTop' + '.png', crop)\n",
    "    \n",
    "    #Center Top Crop\n",
    "    crop = image[:96, 16:112]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'centerTop' + '.png', crop)\n",
    "    \n",
    "    #Right Top Crop\n",
    "    crop = image[:96, 32:]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'rightTop' + '.png', crop)\n",
    "    \n",
    "    #Left Center Crop\n",
    "    crop = image[16:112, :96]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'leftCenter' + '.png', crop)\n",
    "    \n",
    "    #Center Center Crop\n",
    "    crop = image[16:112, 16:112]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'centerCenter' + '.png', crop)\n",
    "    \n",
    "    #Right Center Crop\n",
    "    crop = image[16:112, 32:]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'rightCenter' + '.png', crop)\n",
    "    \n",
    "    #Left Bottom Crop\n",
    "    crop = image[32:, :96]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'leftBottom' + '.png', crop)\n",
    "    \n",
    "    #Center Bottom Crop\n",
    "    crop = image[32:, 16:112]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'centerBottom' + '.png', crop)\n",
    "    \n",
    "    #Right Bottom Crop\n",
    "    crop = image[32:, 32:]\n",
    "    crop = cv2.resize(crop, (128, 128))\n",
    "    cv2.imwrite(filename[:-4] + 'rightBottom' + '.png', crop)\n",
    "\n",
    "# no need to run this block anymore after data augmentation is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"MIT-BIH_DATABASE/train\"\n",
    "valid_path = \"MIT-BIH_DATABASE/valid\"\n",
    "test_path = \"MIT-BIH_DATABASE/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "augment_dirs = ['APC/', 'LBBB/', 'PAB/', 'PVC/', 'RBBB/', 'VEB/', 'VFE/']\n",
    "\n",
    "for image_dir in augment_dirs:\n",
    "    path, dirs, files = next(os.walk(os.path.join(train_path,image_dir)))\n",
    "    for file in tqdm(files):\n",
    "        imagefilepath = os.path.join(train_path,image_dir,file)\n",
    "        image = cv2.imread(imagefilepath)\n",
    "        cropping(image, imagefilepath)\n",
    "\n",
    "# no need to run this block anymore after data augmentation is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the length of different directory inside dataset\n",
    "\n",
    "image_dirs = ['APC/', 'LBBB/', 'NOR/', 'PAB/', 'PVC/', 'VEB/', 'RBBB/', 'VFE/']\n",
    "no_of_files_in_dir=[]\n",
    "for image_dir in image_dirs:\n",
    "    path, dirs, files = next(os.walk(os.path.join(train_path,image_dir)))\n",
    "    no_of_files_in_dir.append(len(files)) \n",
    "\n",
    "print('Number of images in each directory={} and total number of images={}'.format(no_of_files_in_dir, sum(no_of_files_in_dir)))\n",
    "\n",
    "labels = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'VEB', 'RBBB', 'VFE']\n",
    "colors = ['green','blue','red','skyblue','orange', 'yellow','magenta', 'cyan']\n",
    "\n",
    "plot_pie_chart_of_data(no_of_files_in_dir, labels, colors, 'data_distribution_after_augmentation.png')\n",
    "\n",
    "# no need to run this block anymore after data folder (train, test) creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data images into train, test subdirectory\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "image_dirs = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'RBBB', 'VEB', 'VFE']\n",
    "\n",
    "if os.path.isdir('MIT-BIH_DATABASE/valid/APC') is False:\n",
    "    for i in image_dirs:\n",
    "        current_path = 'MIT-BIH_DATABASE/train/'+i\n",
    "        path_valid = 'MIT-BIH_DATABASE/valid/'+i\n",
    "        os.makedirs(path_valid)\n",
    "        path, dirs, files = next(os.walk(current_path))\n",
    "        no_of_files = len(files)\n",
    "        no_of_valid_dir_files = round(no_of_files*0.2)\n",
    "        print(no_of_files)\n",
    "        for j in random.sample(glob.glob(current_path+'/fig*'),no_of_valid_dir_files):\n",
    "            shutil.move(j,path_valid)\n",
    "        \n",
    "        \n",
    "# moving 20% data from MIT-BIH_DATABASE/train/ directory to MIT-BIH_DATABASE/valid subdirectory \n",
    "\n",
    "# no need to run this block anymore after validation data folder (valid) creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the length of datas in valid directory inside dataset\n",
    "Database_DIR = 'MIT-BIH_DATABASE/valid/'\n",
    "image_dirs = ['APC/', 'LBBB/', 'NOR/', 'PAB/', 'PVC/', 'VEB/', 'RBBB/', 'VFE/']\n",
    "no_of_files_in_dir=[]\n",
    "for image_dir in image_dirs:\n",
    "    path, dirs, files = next(os.walk(os.path.join(Database_DIR,image_dir)))\n",
    "    no_of_files_in_dir.append(len(files)) \n",
    "\n",
    "print('Number of images in each directory={} and total number of images={}'.format(no_of_files_in_dir, sum(no_of_files_in_dir)))\n",
    "\n",
    "labels = ['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'VEB', 'RBBB', 'VFE']\n",
    "colors = ['green','blue','red','skyblue','orange', 'yellow','magenta', 'cyan']\n",
    "\n",
    "plot_pie_chart_of_data(no_of_files_in_dir, labels, colors, 'data_distribution_valid_dir.png')\n",
    "\n",
    "# no need to run this block anymore after validation data folder (valid) creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size*epoch = number_of_iteration*batch_size\n",
    "\n",
    "batchSize = 32\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "valid_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_gen.flow_from_directory(directory=train_path, target_size=(128,128), classes=['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'RBBB', 'VEB', 'VFE'], batch_size=batchSize, seed=7)\n",
    "valid_batches = train_gen.flow_from_directory(directory=valid_path, target_size=(128,128), classes=['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'RBBB', 'VEB', 'VFE'], batch_size=batchSize, seed=7)\n",
    "test_batches = test_gen.flow_from_directory(directory=test_path, target_size=(128,128), classes=['APC', 'LBBB', 'NOR', 'PAB', 'PVC', 'RBBB', 'VEB', 'VFE'], batch_size=batchSize, seed=7, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr, batchSize, subplot_dim=[1,10]):\n",
    "    fig, axes = plt.subplots(subplot_dim[0], subplot_dim[1], figsize=(20,20))\n",
    "    axes = axes.flatten()  # flaten converts an array to a 1D vector\n",
    "    for img, ax in zip(images_arr,axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking (train) images and labels of only one batch (32 images,32 labels) and plot them\n",
    "\n",
    "imgs, labels = next(train_batches)\n",
    "plotImages(imgs, batchSize, [4,8])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "def proposed_model(input_h, input_w, nb_classes):\n",
    "    InputShape = (input_h, input_w, 3)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(filters=64, kernel_size=(3,3), activation='elu', kernel_regularizer=regularizers.l1_l2(0.0001, 0.0001) ,padding='same', input_shape=InputShape, kernel_initializer='glorot_uniform'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), activation='elu', kernel_regularizer=regularizers.l2(0.0001), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides= 2),\n",
    "        Dropout(rate=0.2),\n",
    "        \n",
    "        Conv2D(filters=128, kernel_size=(3,3), activation='elu', kernel_regularizer=regularizers.l2(0.0001), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=128, kernel_size=(3,3), activation='elu', kernel_regularizer=regularizers.l2(0.0001), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides= 2),\n",
    "        Dropout(rate=0.2),\n",
    "        \n",
    "        Conv2D(filters=256, kernel_size=(3,3), activation='elu', kernel_regularizer=regularizers.l2(0.0001), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=256, kernel_size=(3,3), activation='elu', kernel_regularizer=regularizers.l2(0.0001), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2), strides= 2),\n",
    "        Dropout(rate=0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(units=2048, activation='elu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(rate=0.5),\n",
    "        Dense(units=nb_classes, activation='softmax'),\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = proposed_model(128, 128, 8)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model.compile(optimizer=Adam(learning_rate= lr), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "Epoch = 2\n",
    "Verbose = 1\n",
    "\n",
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=Epoch, verbose=Verbose, shuffle=True)\n",
    "\n",
    "# save model (architecture, optimizer, weights, ...all)\n",
    "if os.path.isdir('models') is False:\n",
    "    os.makedirs('models')\n",
    "if os.path.isfile('models/ecg_arrgythmia_detection_model.h5') is False:\n",
    "    model.save('models/ecg_arrgythmia_detection_model.h5')\n",
    "    print('model saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/ecg_arrgythmia_detection_model.h5')\n",
    "#prev_saved_model = load_model('models/cnn.h5')\n",
    "\n",
    "print(model.summary())\n",
    "# print(prev_saved_model.get_weights())\n",
    "# print(prev_saved_model.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "Epoch = 20\n",
    "Verbose = 1\n",
    "\n",
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=Epoch, verbose=Verbose, shuffle=True)\n",
    "model.save('models/ecg_arrgythmia_detection_model.h5')\n",
    "print('model saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/ecg_arrgythmia_detection_model_36_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = 2\n",
    "Verbose = 1\n",
    "\n",
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=Epoch, verbose=Verbose, shuffle=True)\n",
    "model.save('models/ecg_arrgythmia_detection_model_37_epoch.h5')\n",
    "print('model saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "\n",
    "predictions = model.predict(x = test_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test results\n",
    "results = model.evaluate(x = test_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_batches.classes\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix_custom(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\" prints and plots confusion matrix. \n",
    "        normalization can be applied by setting `normalize=True` \"\"\"\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized confusion matrix')\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization ')\n",
    "    \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max()/2\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('confusion.jpg', dpi=400, pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix output\n",
    "cm = confusion_matrix(y_true = test_labels, y_pred = rounded_predictions)\n",
    "cm_plot_lables = ['NOR', 'LBBB', 'RBBB', 'APC', 'PVC', 'VEB','PAB', 'VFE']\n",
    "# non normalized confusion matrix\n",
    "#plot_confusion_matrix_custom(cm = cm, classes = cm_plot_lables)\n",
    "\n",
    "# normalized confusion matrix\n",
    "plot_confusion_matrix_custom(cm = cm, classes = cm_plot_lables, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report_result = classification_report(test_labels, rounded_predictions, target_names=cm_plot_lables)\n",
    "print(classification_report_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
